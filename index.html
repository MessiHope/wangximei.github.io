<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta name="google-site-verification" content="R8k7TsCqBjqxIhtX3uQzrcOtMe2MsQWDWjGzJokGbjM" />    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Ximei Wang, 王希梅, Transfer Learning, Domain Adaptation, Deep Learning, Machine Learning, Computer Science, Tsinghua University, Tencent">
    <title>Ximei Wang - Tsinghua University</title>
    <link rel="stylesheet" href="./src/bootstrap.css">
    <link rel="stylesheet" href="./src/style.css">
    <script async="" src="file://www.google-analytics.com/analytics.js"></script><script async="" src="./src/analytics.js"></script><script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create','UA-2176015958-1','tsinghua.edu.cn');
        ga('send','pageview');
    </script>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
    </script>
</head>

<body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
    <div class="container">
        <div class="row">
            <div class="col-md-12 top-buffer">
                <h2 class="bottom-buffer">Ximei Wang </h2><hr>
            </div>
        </div>
        <div class="row">
            <div class="col-md-2">
                <img class="img-responsive" src="./src/wangximei.jpeg" alt="Ximei Wang">
            </div>
            <div class="col-md-10">
                <p>
                I am currently a senior researcher in <a href="https://www.tencent.com/zh-cn/">Tencent</a>, focusing on dataset shift in machine learning, especially transfer learning, domain adaptation, cross-domain recommendation, multi-domain learning and multi-task learning. Prior to that, I received my Ph.D. degree from <a href="http://www.thss.tsinghua.edu.cn/">School of Software</a>, <a href="http://www.tsinghua.edu.cn/">Tsinghua University</a>, advised by Prof. <a href="https://www.thss.tsinghua.edu.cn/faculty/wangjianmin.htm">Jianmin Wang</a> and Prof. <a href="http://ise.thss.tsinghua.edu.cn/~mlong/">Mingsheng Long</a>. During my Ph.D. study, I was a research intern in Tencent for a year, mentored by <a href="https://scholar.google.com/citations?user=sUaBkFkAAAAJ&hl=zh-TW">Junwei Pan</a>. I received my B.S. degree from <a href="http://www.au.tsinghua.edu.cn/">Department of Automation</a>, <a href="http://www.tsinghua.edu.cn/">Tsinghua University</a>.
                </p>
                <p> messixmwang [AT] tencent.com, wxm17 [AT] tsinghua.org.cn <br>
                    [<a target='_blank' href='https://scholar.google.com/citations?user=WmOCCVgAAAAJ&hl=en'>Google Scholar</a>]
                    [<a target='_blank' href='https://www.semanticscholar.org/author/Ximei-Wang/2561964'>Semantic Scholar</a>]
                    [<a target='_blank' href='https://www.researchgate.net/profile/Ximei_Wang3'>ResearchGate</a>]
                <br> Binhai Building, Tencent, Shenzhen, China</p>
            </div>
        </div>


       <h3>Education</h3><hr>
            <ul>
                <li>
                    <p>Ph.D. in Software Engineering, 2017-2022<br>
                    <a href="http://www.thss.tsinghua.edu.cn/">School of Software</a>, <a href="http://www.tsinghua.edu.cn/">Tsinghua University</a>, Beijing, China<br>
                </p>
                </li>
                
                <li>
                    <p>Bachelor in Automation, 2013-2017<br>
                    <a href="http://www.au.tsinghua.edu.cn/">Department of Automation</a>, <a href="http://www.tsinghua.edu.cn/">Tsinghua University</a>, Beijing, China</p>
                </li>
            </ul>


        <h3>Preprint</h3>
        (<em>* Equal Contribution</em>, <em># Corresponding Author</em>)
         <hr>
           <ol>
                <li>
                    <p><strong>Bi-tuning of Pre-trained Representations</strong><br>
                        Jincheng Zhong*, <strong>Ximei Wang</strong>*, Zhi Kou, Jianmin Wang, Mingsheng Long# [<a href="https://arxiv.org/abs/2011.06182">arXiv 2020</a>]             </p>
                </li>

            </ol>



        <h3>Publications</h3>
        (<em>* Equal Contribution</em>, <em># Corresponding Author</em>)
        <hr>
            <ol>
                <li>
                    <p><strong>Debiased Self-Training for Semi-Supervised Learning</strong><br>
                            Baixu Chen, Junguang Jiang, <strong>Ximei Wang</strong>, Pengfei Wan, Jianmin Wang, Mingsheng Long<br>
                            <em>Neural Information Processing Systems (<a href="http://nips.cc/Conferences/2022"><strong>NeurIPS</strong></a>)</em>, 2022 [<a href="https://arxiv.org/abs/2202.07136">arXiv</a>]</p>
                </li>

                <li>
                    <p><strong>X-model: Improving Data Efficiency in Deep Learning with A Minimax Model</strong><br>
                        <strong>Ximei Wang</strong>, Xinyang Chen, Jianmin Wang, Mingsheng Long<br>
                        <em>International Conference on Learning Representations (<a href="https://iclr.cc/Conferences/2022"><strong>ICLR</strong></a>)</em>, 2022 [<a href="https://openreview.net/forum?id=P3Bh01hBYTH">OpenReview</a>]</p>
                </li>

                <li>
                    <p><strong>Self-Tuning for Data-Efficient Deep Learning</strong><br>
                        <strong>Ximei Wang*</strong>, Jinghan Gao*, Jianmin Wang, Mingsheng Long# <br>
                        <em>International Conference on Machine Learning (<a href="https://icml.cc/"><strong>ICML</strong></a>)</em>, 2021 [<a href="https://arxiv.org/abs/2102.12903">PDF</a>] [<a href="https://github.com/thuml/Self-Tuning">Code</a>] [<a href="https://github.com/thuml/Self-Tuning/blob/master/Self-Tuning-Slide.pdf">Slide</a>] [<a href="https://icml.cc/virtual/2021/spotlight/8616">Video</a>] [<a href="https://github.com/thuml/Self-Tuning/blob/master/Self-Tuning-Poster.png">Poster</a>] [<a href="https://mp.weixin.qq.com/s/H4xlndTZtWuXHni-vOC_vQ">Blog</a>] [<a href="https://zhuanlan.zhihu.com/p/393342161">Zhihu</a>] [<a href="https://recorder-v3.slideslive.com/#/share?share=40334&s=f7988e61-bece-4a7a-a6ba-3e1a2b49b37b">SlidesLive</a>]
                    </p>            
                    </p>
                </li>

                <li>
                    <p><strong>Transferable Calibration with Lower Bias and Variance in Domain Adaptation</strong><br>
                        <strong>Ximei Wang</strong>, Mingsheng Long#, Jianmin Wang, Michael I. Jordan<br>
                        <em>Neural Information Processing Systems (<a href="http://nips.cc/Conferences/2020"><strong>NeurIPS</strong></a>)</em>, 2020 [<a href="https://papers.nips.cc/paper/2020/file/df12ecd077efc8c23881028604dbb8cc-Paper.pdf">PDF</a>] [<a href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/transferable-calibration-supp-nips20.pdf">Appendix</a>] [<a href="https://github.com/thuml/TransCal">Code</a>] [<a href="https://github.com/thuml/TransCal/blob/master/TransCal-poster.pdf">Poster</a>] [<a href="https://github.com/thuml/TransCal/blob/master/TransCal-slide.pdf">Slide</a>] [<a href="https://neurips.cc/virtual/2020/protected/poster_df12ecd077efc8c23881028604dbb8cc.html">Video</a>]</p> 
                </li>

                <li>
                    <p><strong>Transferable Normalization: Towards Improving Transferability of Deep Neural Networks</strong><br>
                    <strong>Ximei Wang</strong>, Ying Jin, Mingsheng Long#, Jianmin Wang, Michael I. Jordan<br>
                    <em>Neural Information Processing Systems (<a href="http://nips.cc/Conferences/2019"><strong>NeurIPS</strong></a>)</em>, 2019 [<a href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/transferable-normalization-nips19.pdf">PDF</a>] [<a href="https://github.com/thuml/TransNorm">Code</a>] [<a href="https://github.com/thuml/TransNorm/blob/master/TransNorm-poster.pdf">Poster</a>] [<a href="https://github.com/thuml/TransNorm/blob/master/TransNorm-slide.pdf">Slide</a>]</p>
                </li>

                 <li>
                    <p><strong>Transferable Attention for Domain Adaptation</strong><br>
                        <strong>Ximei Wang</strong>, Liang Li, Weirui Ye, Mingsheng Long#, Jianmin Wang<br>
                        <em>AAAI Conference on Artificial Intelligence (<a href="https://aaai.org/Conferences/AAAI-19/"><strong>AAAI</strong></a>)</em>, 2019 [<a href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/transferable-attention-aaai19.pdf">PDF</a>] (<em>Oral Presentation</em>)</p>
                    </li>

                <li>
                    <p><strong>Regressive Domain Adaptation for Unsupervised Keypoint Detection</strong><br>
                        Junguang Jiang, Yifei Ji, <strong>Ximei Wang</strong>, Yufeng Liu, Jianmin Wang, Mingsheng Long<br>
                        <em>IEEE Conference on Computer Vision and Pattern Recognition (<a href="http://cvpr2021.thecvf.com/"><strong>CVPR</strong></a>)</em>, 2021 [<a href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/regressive-domain-adaptation-cvpr21.pdf">PDF</a>] [<a href="https://github.com/thuml/Transfer-Learning-Library">Code</a>]
                    </p>
                </li>

                
                <li>
                    <p><strong>Resource Efficient Domain Adaptation</strong><br>
                    Junguang Jiang, <strong>Ximei Wang</strong>, Mingsheng Long#, Jianmin Wang<br>
                    <em>ACM International Conference on Multimedia (<a href="http://www.acmmm.org/2020/"><strong>ACMMM</strong></a>)</em>, 2020  [<a href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/resource-efficient-domain-adaptation-acmmm20.pdf">PDF</a>] [<a href="https://github.com/thuml/Transfer-Learning-Library">Code</a>]</p>
                </li>

                <li>
                    <p><strong>Minimum Class Confusion for Versatile Domain Adaptation</strong><br>
                    Ying Jin, <strong>Ximei Wang</strong>, Mingsheng Long#, Jianmin Wang<br>
                    <em>European Conference on Computer Vision (<a href="https://eccv2020.eu/"><strong>ECCV</strong></a>)</em>, 2020 [<a href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/versatile-domain-adaptation-eccv20.pdf">PDF</a>] [<a href="https://github.com/thuml/Versatile-Domain-Adaptation">Code</a>]</p>
                </li>

                <li>
                    <p><strong>Towards Accurate Model Selection in Deep Unsupervised Domain Adaptation</strong><br>
                    Kaichao You, <strong>Ximei Wang</strong>, Mingsheng Long#, Michael I. Jordan<br>
                    <em>International Conference on Machine Learning (<a href="https://icml.cc/"><strong>ICML</strong></a>)</em>, 2019 [<a href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/deep-embedded-validation-icml19.pdf">PDF</a>] [<a href="https://github.com/thuml/Deep-Embedded-Validation">Code</a>]</p>
                </li>
            </ol>


            <h3>Teaching Assistant (TA)</h3><hr>
            <ul>
                <li><em>Deep Learning</em>, Graduate Course, Spring 2019, 2020, 2021 (<strong>Top 5% outstanding TA for three years in succession </strong>)</li>
                <li><em>Introduction to Data Science</em>, Undergraduate Course, Fall 2018, 2019 (<strong>Top 5% outstanding TA in 2019 </strong>)</li>
                <li><em>Big Data Technologies and Applications</em>, Undergraduate Course, Fall 2018</li>
            </ul>


        <h3>Professional Services</h3><hr>           
            <h4>Program Committee Member</h4>
                <ul>
                	<li>Neural Information Processing Systems (NeurIPS), 2020, 
                        <a href="https://nips.cc/Conferences/2020/Reviewers">
                            <strong>In the Top 10% of High-Scoring Reviewers</strong>
                        </a>
                    </li>
                    <li>Neural Information Processing Systems (NeurIPS), 2021,
                        <a href="https://nips.cc/Conferences/2021/Reviewers">
                            <strong>Top 8% Outstanding Reviewer Award</strong>
                        </a>
                    </li>

                    <li>International Conference on Machine Learning (ICML), 
                        <a href="https://icml.cc/Conferences/2021/Reviewers">
                            <strong>Expert Reviewer, Best Reviewers (Top 10%)</strong>
                        </a>, 2021
                    </li>

                	<li>International Conference on Learning Representations (ICLR), 
                        <a href="https://iclr.cc/Conferences/2021/Reviewers">
                            <strong>Outstanding Reviewer</strong>
                        </a>, 2021
                    </li>

                    <li>Neural Information Processing Systems (NeurIPS), 2022
                    </li>

                    <li>International Conference on Machine Learning (ICML), 2021, 2022
                    </li>

                    <li>International Conference on Learning Representations (ICLR), 2022, 2023
                    </li>

                	<li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021, 2022</li>
                    <li>IEEE International Conference on Computer Vision (ICCV), 2021</li>
                    <li>International Joint Conference on Artificial Intelligence (IJCAI), 2020</li>
                </ul>
            <h4>Peer Reviewer</h4>
                <ul>
                    <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020, 2021, 2022</li>
                    <li>IEEE Transactions on Image Processing (TIP), 2020</li>
                    <li>International Journal of Computer Vision (IJCV), 2020</li>
                </ul>

        <h3>Awards</h3><hr>
            <ul>
                <li>Outstanding PhD Graduate in Beijing (北京市优秀毕业生), 2022</li>
                <li>Outstanding PhD Graduate in School of Software, Tsinghua University (软件学院优秀毕业生), 2022</li>
                <li>Tsinghua Software Scholarship, Tsinghua University, 2022</li>
                <li>National Scholarship for PhDs, Ministry of Education, 2021</li>
                <li>First Prize, Toyota Scholarship, Tsinghua University, 2020</li>
                <li>Huawei Scholarship, Tsinghua University, 2019</li>
                <li>Second Prize, Award on Outstanding Research, Machine Learning Group, Tsinghua University, 2018, 2019</li>
                <li>First Prize, Outstanding Contribution Award, National Engineering Laboratory for BDSS, 2017, 2018</li>
            </ul>
        <hr>
        <footer>
        <p>Last updated: <script type="text/javascript">document.write(document.lastModified);</script>.

        &emsp;
        <span id="busuanzi_container_site_pv">Totol Visits: <span id="busuanzi_value_site_pv"></span> times</span>

        &emsp;
        <span id="busuanzi_container_site_uv">Total Visitors: <span id="busuanzi_value_site_uv"></span> persons</span>



</body></html>
